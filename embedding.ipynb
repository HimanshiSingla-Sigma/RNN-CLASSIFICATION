{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de41a34a",
   "metadata": {},
   "source": [
    "1. One-Hot Encoding ki Kami (Sparse Data)\n",
    "Pahle hum words ko aise likhte the:\n",
    "\n",
    "Apple = [1, 0, 0, 0]\n",
    "\n",
    "Orange = [0, 1, 0, 0]\n",
    "\n",
    "Isme do badi mushkilein thi:\n",
    "\n",
    "Size: Agar aapki dictionary mein 10,000 words hain, toh har ek word ke liye 10,000 numbers ki list banani padegi. Ye memory bahut consume karta hai.\n",
    "\n",
    "Relationship: Is method mein \"Apple\" aur \"Orange\" ke beech koi rishta nahi dikhta. Computer ko lagta hai \"Apple\" aur \"Sky\" jitne alag hain, \"Apple\" aur \"Orange\" bhi utne hi alag hain.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Embedding ka Jadoo (Dense & Meaningful)\n",
    "Embedding words ko ek \"Vector Space\" mein rakhti hai. Iske 3 bade fayde hain:\n",
    "\n",
    "A. Similarity (Rishtey Samjhna)\n",
    "Embedding mein milte-julte words ek-dusre ke paas hote hain.\n",
    "\n",
    "\"King\" aur \"Queen\" paas honge.\n",
    "\n",
    "\"Diabetes\" aur \"Glucose\" paas honge.\n",
    "Isse aapka model ye samajh jata hai ki agar user \"Sugar\" bol raha hai, toh uska matlab \"Glucose\" se hi hai.\n",
    "\n",
    "B. Dimensions (Gehraai)\n",
    "Jaise hum ek insaan ko define karte hain (Height, Weight, Age), waise hi Embedding har word ko 32 ya 100 features mein tod deti hai.\n",
    "\n",
    "Ek dimension \"Fruit\" ka ho sakta hai.\n",
    "\n",
    "Ek dimension \"Color\" ka ho sakta hai.\n",
    "\"Apple\" aur \"Orange\" ka \"Fruit\" waala number match karega, isliye model unhe ek category mein rakhega.\n",
    "\n",
    "C. Memory Bachana\n",
    "Jahan One-Hot 10,000 numbers leta tha, Embedding wahi kaam sirf 32 ya 64 numbers (dense vectors) mein kar leti hai. Isse model fast chalta hai aur memory kam leta hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "697f21fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36 241 112 170   0]\n",
      " [  7 227  16 433   0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# 1. Sample Data\n",
    "reviews = ['The movie was amazing', 'Total waste of time']\n",
    "\n",
    "# iska matlb hai that we want every word to be first converted to numbers between 0-499 and should be \n",
    "# given an index between it \n",
    "vocab_size = 500  # Range of numbers for hashing \n",
    "\n",
    "# 2. Convert to One-Hot (Integers)\n",
    "# Iska naam one_hot hai, par ye actually \"integer indices\" deta hai\n",
    "# one_hot converts every word to an integer index based upon the vocabulary size\n",
    "encoded_reviews = [one_hot(text, vocab_size) for text in reviews]\n",
    "\n",
    "# 3. Padding (Sabki length barabar karne ke liye)\n",
    "max_length = 5\n",
    "# now every sentence has different lenght but for rnn every sentence should have same length\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "\n",
    "print(padded_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f34ae8",
   "metadata": {},
   "source": [
    "#### why not sentence-transformers for LSTM and RNN instead of Embedding layer of tensorflow.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce37990",
   "metadata": {},
   "source": [
    "1. \"Internal\" vs \"External\" Embedding\n",
    "Keras Embedding Layer: Ye model ke andar hoti hai. Jab aap model train karte hain, toh ye layer aapke specific data (movie reviews ya medical terms) ke hisaab se words ka matlab khud seekhti hai.\n",
    "\n",
    "Sentence Transformers: Ye bahar se aate hain. Ye pehle se millions of sentences par trained hain. Inhe use karne ke liye aapko pehle text ko vectors mein badalna padega, phir wo vectors LSTM ko dene honge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08c154",
   "metadata": {},
   "source": [
    "2. Architecture ka Farq (Words vs Sentences)\n",
    "LSTM ka kaam: LSTM sequence ko \"word-by-word\" padhta hai. Use har step par ek word ka vector chahiye hota hai.\n",
    "\n",
    "Sentence Transformer ka kaam: Iska maqsad pure sentence ka ek single vector banana hota hai.\n",
    "\n",
    "Agar aap pure sentence ka vector bana denge, toh LSTM ko dene ke liye \"sequence\" bachegi hi nahi! Phir aapko LSTM ki zaroorat hi nahi padegi, aap seedha ek simple Dense Layer use kar sakte hain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ec1d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jiya computers\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jiya computers\\anaconda3\\envs\\tf_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:103: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    # input_dim is your vocab_size\n",
    "    Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length,input_shape=(max_length,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde76b65",
   "metadata": {},
   "source": [
    "2. Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length)\n",
    "Ye layer sabse important hai kyunki ye Words ko Numbers mein badalti hai.\n",
    "\n",
    "input_dim=vocab_size: Aapki dictionary mein total kitne words hain? Agar aapne 500 rakha hai, toh model sirf 500 unique words ko pehchanega.\n",
    "\n",
    "output_dim=32: Har word ko kitne numbers se describe karna hai? Jaise ek insaan ko height, weight, aur age se describe karte hain, waise hi yahan har word ko 32 alag-alag features (numbers) milenge. Isse model ko \"Good\" aur \"Great\" ke beech ka connection samajh aata hai.\n",
    "\n",
    "input_length=max_length: Ek review mein maximum kitne words honge? Agar user ne 10 words likhe aur aapka max_length=5 hai, toh ye sirf pehle 5 words lega."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c0487c",
   "metadata": {},
   "source": [
    "LSTM(64)\n",
    "Ye aapke model ka \"Memory Cell\" ya \"Dimag\" hai.\n",
    "\n",
    "64 (Units): Iska matlab hai ki model ke paas 64 \"dimagi nasien\" (neurons) hain jo sequence ko yaad rakhti hain.\n",
    "\n",
    "Kaam: LSTM sentence ko shuru se end tak padhta hai. Agar sentence hai \"The movie was not good\", toh LSTM yaad rakhega ki \"good\" se pehle \"not\" aaya tha, isliye iska matlab negative hai. Simple RNN ye aksar bhool jata hai, par LSTM yaad rakhta hai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4ec50",
   "metadata": {},
   "source": [
    "4. Dense(1, activation='sigmoid')Ye final \"Decision Maker\" layer hai.1: Humein sirf ek final answer chahiye (Ki review positive hai ya negative).activation='sigmoid': Ye ek filter hai jo result ko 0 aur 1 ke beech le aata hai.Agar result 0.8 aaya $\\rightarrow$ Matlab 80% chance hai ki review Positive hai.Agar result 0.2 aaya $\\rightarrow$ Matlab review Negative hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e545d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb512fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m16,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> (62.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,000\u001b[0m (62.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,000</span> (62.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,000\u001b[0m (62.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e4bb572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.04456632, -0.00750878,  0.04759869, -0.01851822,\n",
       "         -0.00873413, -0.04987632,  0.00406854, -0.03519976,\n",
       "         -0.00211903,  0.00092519,  0.03283632,  0.0207273 ,\n",
       "         -0.0460847 , -0.04569472, -0.02675011, -0.00558486,\n",
       "          0.02653401,  0.00088926,  0.00463434, -0.01090608,\n",
       "         -0.02194557, -0.01826362,  0.01472653, -0.01031782,\n",
       "         -0.04495148,  0.04729522, -0.03960258,  0.00525799,\n",
       "         -0.00978957,  0.00914575,  0.02304592, -0.04096989],\n",
       "        [-0.04909236,  0.04885465, -0.02873277, -0.02348728,\n",
       "         -0.01546708, -0.0474305 , -0.01624734,  0.01899756,\n",
       "         -0.02433624, -0.00179497, -0.01582281,  0.02415912,\n",
       "         -0.03897215, -0.04519848,  0.02969139,  0.04172743,\n",
       "          0.00397807, -0.01042148, -0.04584536,  0.02621825,\n",
       "         -0.03939726, -0.02421489, -0.03189909, -0.04971664,\n",
       "          0.03967513,  0.03024052, -0.03661814, -0.01110115,\n",
       "         -0.02595755,  0.03313417, -0.04156876,  0.03931458],\n",
       "        [-0.02947985,  0.02949066, -0.03890799,  0.03475604,\n",
       "          0.03569383, -0.01547105, -0.01386439,  0.02437616,\n",
       "          0.03058403,  0.01519391, -0.00909635,  0.02127602,\n",
       "         -0.0062713 , -0.00506413,  0.01445473, -0.03638253,\n",
       "          0.02391033, -0.00059085, -0.018751  ,  0.01558245,\n",
       "          0.01286888,  0.0476399 , -0.04517292, -0.03262788,\n",
       "         -0.04421717, -0.02141435,  0.01407447,  0.0117755 ,\n",
       "          0.00076701, -0.003828  ,  0.00253043,  0.01930589],\n",
       "        [-0.03715654,  0.04093422,  0.02220346, -0.0367708 ,\n",
       "          0.01680395,  0.01101682,  0.01599434, -0.03228663,\n",
       "          0.04910262, -0.00993346, -0.0418788 ,  0.02354779,\n",
       "         -0.03050444,  0.03358625,  0.0164387 ,  0.03723936,\n",
       "         -0.03581768, -0.00358032,  0.04529151,  0.0489082 ,\n",
       "         -0.02695564,  0.00819856, -0.03629201,  0.02636436,\n",
       "          0.02585925,  0.01150178, -0.01092703, -0.02277735,\n",
       "          0.02345512,  0.01588852, -0.00591217, -0.04136131],\n",
       "        [-0.04796379, -0.0417046 ,  0.01211743,  0.01875689,\n",
       "         -0.00844004, -0.01153428,  0.03399155, -0.0189005 ,\n",
       "          0.0256637 , -0.01075745, -0.01345523, -0.01277503,\n",
       "          0.02086413,  0.0022472 ,  0.00565273,  0.04099328,\n",
       "         -0.02210443,  0.02143965,  0.03996295, -0.04563059,\n",
       "         -0.02326099,  0.03532707, -0.03502139,  0.01333863,\n",
       "          0.037474  , -0.00034373, -0.0333813 , -0.02702773,\n",
       "          0.00449874, -0.02786447,  0.00774221, -0.03864644]],\n",
       "\n",
       "       [[-0.04791265,  0.04084294, -0.01365455,  0.02935176,\n",
       "          0.03405919, -0.02354186,  0.00405867, -0.04850042,\n",
       "         -0.02768677,  0.03700427, -0.0026526 ,  0.00168266,\n",
       "         -0.04744021,  0.04740031,  0.01446111, -0.02294146,\n",
       "          0.01902667, -0.00098912, -0.0371322 , -0.03135858,\n",
       "         -0.04283884, -0.0296615 , -0.03453196, -0.00442314,\n",
       "         -0.01804447,  0.02886856,  0.01742247,  0.0141016 ,\n",
       "         -0.00496439, -0.03899624,  0.04870206,  0.00638839],\n",
       "        [ 0.00325529, -0.01348739,  0.04568844,  0.0043347 ,\n",
       "         -0.03154459,  0.01157962,  0.04394792,  0.03089089,\n",
       "          0.04516908,  0.01915208, -0.01876075,  0.01601763,\n",
       "         -0.00996263, -0.03095353, -0.04642198,  0.02855747,\n",
       "         -0.03331681,  0.02884478,  0.01474432, -0.02767003,\n",
       "          0.02985832, -0.04963442,  0.04069194, -0.03704607,\n",
       "         -0.03623936,  0.03856008,  0.01385874,  0.01091896,\n",
       "          0.00191306,  0.02543009, -0.03427064, -0.01855972],\n",
       "        [ 0.00824913, -0.00944029, -0.02249338, -0.03690793,\n",
       "         -0.01255077,  0.04804173, -0.04261942, -0.00434134,\n",
       "          0.04911906, -0.00812363,  0.00686232, -0.04569579,\n",
       "         -0.04087095, -0.03093401,  0.0290224 , -0.02359724,\n",
       "         -0.01044911, -0.02209797,  0.02751874,  0.03973234,\n",
       "         -0.04899296,  0.03255117, -0.00420616,  0.01351693,\n",
       "         -0.0213631 , -0.0483358 , -0.0346169 ,  0.04758051,\n",
       "          0.00733197,  0.04579744, -0.0103898 ,  0.01186284],\n",
       "        [-0.00286621,  0.02604321, -0.04898883, -0.0031214 ,\n",
       "         -0.01175671,  0.03253956, -0.01465043, -0.04442946,\n",
       "          0.01423306, -0.04940955,  0.01907543, -0.04936584,\n",
       "          0.00863758,  0.0113353 , -0.01386843,  0.0374564 ,\n",
       "          0.02765575,  0.04006937, -0.00814475, -0.0166401 ,\n",
       "          0.01927373, -0.04612733, -0.01193136,  0.03001269,\n",
       "         -0.00305999,  0.01755058,  0.01378561,  0.01452353,\n",
       "         -0.00379205,  0.00166572,  0.04301976,  0.01283715],\n",
       "        [-0.04796379, -0.0417046 ,  0.01211743,  0.01875689,\n",
       "         -0.00844004, -0.01153428,  0.03399155, -0.0189005 ,\n",
       "          0.0256637 , -0.01075745, -0.01345523, -0.01277503,\n",
       "          0.02086413,  0.0022472 ,  0.00565273,  0.04099328,\n",
       "         -0.02210443,  0.02143965,  0.03996295, -0.04563059,\n",
       "         -0.02326099,  0.03532707, -0.03502139,  0.01333863,\n",
       "          0.037474  , -0.00034373, -0.0333813 , -0.02702773,\n",
       "          0.00449874, -0.02786447,  0.00774221, -0.03864644]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f18a454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36, 241, 112, 170,   0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c3abab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
      "[[[-0.04456632 -0.00750878  0.04759869 -0.01851822 -0.00873413\n",
      "   -0.04987632  0.00406854 -0.03519976 -0.00211903  0.00092519\n",
      "    0.03283632  0.0207273  -0.0460847  -0.04569472 -0.02675011\n",
      "   -0.00558486  0.02653401  0.00088926  0.00463434 -0.01090608\n",
      "   -0.02194557 -0.01826362  0.01472653 -0.01031782 -0.04495148\n",
      "    0.04729522 -0.03960258  0.00525799 -0.00978957  0.00914575\n",
      "    0.02304592 -0.04096989]\n",
      "  [-0.04909236  0.04885465 -0.02873277 -0.02348728 -0.01546708\n",
      "   -0.0474305  -0.01624734  0.01899756 -0.02433624 -0.00179497\n",
      "   -0.01582281  0.02415912 -0.03897215 -0.04519848  0.02969139\n",
      "    0.04172743  0.00397807 -0.01042148 -0.04584536  0.02621825\n",
      "   -0.03939726 -0.02421489 -0.03189909 -0.04971664  0.03967513\n",
      "    0.03024052 -0.03661814 -0.01110115 -0.02595755  0.03313417\n",
      "   -0.04156876  0.03931458]\n",
      "  [-0.02947985  0.02949066 -0.03890799  0.03475604  0.03569383\n",
      "   -0.01547105 -0.01386439  0.02437616  0.03058403  0.01519391\n",
      "   -0.00909635  0.02127602 -0.0062713  -0.00506413  0.01445473\n",
      "   -0.03638253  0.02391033 -0.00059085 -0.018751    0.01558245\n",
      "    0.01286888  0.0476399  -0.04517292 -0.03262788 -0.04421717\n",
      "   -0.02141435  0.01407447  0.0117755   0.00076701 -0.003828\n",
      "    0.00253043  0.01930589]\n",
      "  [-0.03715654  0.04093422  0.02220346 -0.0367708   0.01680395\n",
      "    0.01101682  0.01599434 -0.03228663  0.04910262 -0.00993346\n",
      "   -0.0418788   0.02354779 -0.03050444  0.03358625  0.0164387\n",
      "    0.03723936 -0.03581768 -0.00358032  0.04529151  0.0489082\n",
      "   -0.02695564  0.00819856 -0.03629201  0.02636436  0.02585925\n",
      "    0.01150178 -0.01092703 -0.02277735  0.02345512  0.01588852\n",
      "   -0.00591217 -0.04136131]\n",
      "  [-0.04796379 -0.0417046   0.01211743  0.01875689 -0.00844004\n",
      "   -0.01153428  0.03399155 -0.0189005   0.0256637  -0.01075745\n",
      "   -0.01345523 -0.01277503  0.02086413  0.0022472   0.00565273\n",
      "    0.04099328 -0.02210443  0.02143965  0.03996295 -0.04563059\n",
      "   -0.02326099  0.03532707 -0.03502139  0.01333863  0.037474\n",
      "   -0.00034373 -0.0333813  -0.02702773  0.00449874 -0.02786447\n",
      "    0.00774221 -0.03864644]]]\n"
     ]
    }
   ],
   "source": [
    "# Yeh sahi tareeka hai\n",
    "prediction = model.predict(padded_reviews[0:1])\n",
    "print(prediction) # word embedding of first sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04973b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
